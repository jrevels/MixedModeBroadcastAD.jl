These files show the generated code for MixedModeBroadcastAD 572796f with Julia
de705f3b69 running on cyclops (CUDA 9.1.85, driver 390.30) on a Tesla V100, vs
Python 3.6.3 with TensorFlow 1.5.0 (using XLA). On Julia, IR and PTX code is
collected with respectively `@device_code_llvm dump_module=true` and
`@device_code_ptx`, while TensorFlow code is acquired using
`TF_XLA_FLAGS='--xla_dump_ir_to=...'`. SASS code is generated using `ptxas
--gpu-name sm_XX` (`sm_XX` according to target in the PTX source) and `cuobjdump
--dump-sass`, and clean-up using `sed -i 's#\s*/\*[^*]*\*/##g'`. Do note that
using tools from the CUDA toolkit might (and does) yield slightly different code
from the SASS generated by the driver's JIT (as inspected with `nvvp`).

For Julia, `_linear` code dumps are from the `tb/linear_broadcast_2` branch,
which uses linear indexing instead of fully-general broadcasting. As we actually
do broadcast differently-shaped containers, this branch results in memory
errors, which is why there's only a couple of kernels available in linear
format. Despite the code being wrong, it does paint a clearer picture of what's
happening without the index selection bloat as generated by the
broadcast/CartesianIndex machinery.

Ultimately, although we're generating reasonably clean code in the linear case,
there's much more cruft when doing fully-generic broadcasts. On the V100, a
powerful GPU, this does not seem to impact performance; the latency of the added
compute is presumably sufficiently hidden by memory operations. I assume this
might not be the case on older hardware.
