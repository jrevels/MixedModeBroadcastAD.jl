//
// Generated by LLVM NVPTX Back-End
//

.version 5.0
.target sm_60
.address_size 64

    // .globl   tanh_1
.visible .entry tanh_1(
    .param .u64 tanh_1_param_0,
    .param .u64 tanh_1_param_1,
    .param .u64 tanh_1_param_2
)
.reqntid 64, 1, 1
{
    .reg .pred  %p<4>;
    .reg .f32   %f<25>;
    .reg .b32   %r<10>;
    .reg .b64   %rd<10>;

    ld.param.u64    %rd3, [tanh_1_param_0];
    ld.param.u64    %rd4, [tanh_1_param_1];
    cvta.to.global.u64  %rd1, %rd4;
    cvta.to.global.u64  %rd5, %rd3;
    mov.u32     %r1, %ctaid.x;
    mov.u32     %r2, %tid.x;
    shl.b32     %r3, %r1, 6;
    or.b32      %r4, %r3, %r2;
    cvt.u64.u32     %rd2, %r4;
    mul.wide.u32    %rd6, %r4, 4;
    add.s64     %rd7, %rd5, %rd6;
    ld.global.nc.f32    %f1, [%rd7];
    abs.f32     %f2, %f1;
    setp.lt.f32     %p1, %f2, 0f3F0CCCCD;
    @%p1 bra    LBB4_2;
    bra.uni     LBB4_1;
LBB4_2:
    mul.f32     %f17, %f1, %f1;
    fma.rn.f32  %f18, %f17, 0f3C86A81B, 0fBD57BE66;
    fma.rn.f32  %f19, %f18, %f17, 0f3E08677B;
    fma.rn.f32  %f20, %f19, %f17, 0fBEAAAA29;
    mul.f32     %f21, %f17, %f20;
    fma.rn.f32  %f22, %f21, %f1, %f1;
    setp.eq.f32     %p3, %f1, 0f00000000;
    add.f32     %f23, %f1, %f1;
    selp.f32    %f24, %f23, %f22, %p3;
    shl.b64     %rd8, %rd2, 2;
    add.s64     %rd9, %rd1, %rd8;
    st.global.f32   [%rd9], %f24;
    ret;
LBB4_1:
    add.f32     %f8, %f2, %f2;
    mul.f32     %f9, %f8, 0f3FB8AA3B;
    cvt.rzi.f32.f32     %f10, %f9;
    fma.rn.f32  %f11, %f10, 0fBF317200, %f8;
    fma.rn.f32  %f12, %f10, 0fB5BFBE8E, %f11;
    mul.f32     %f13, %f12, 0f3FB8AA3B;
    ex2.approx.ftz.f32  %f14, %f13;
    ex2.approx.f32  %f15, %f10;
    fma.rn.f32  %f7, %f14, %f15, 0f3F800000;
    // begin inline asm
    rcp.approx.ftz.f32 %f6,%f7;
    // end inline asm
    fma.rn.f32  %f16, %f6, 0fC0000000, 0f3F800000;
    setp.ge.f32     %p2, %f2, 0f42B00000;
    mov.b32     %r5, %f16;
    selp.b32    %r6, 1065353216, %r5, %p2;
    mov.b32     %r7, %f1;
    and.b32     %r8, %r7, -2147483648;
    or.b32      %r9, %r6, %r8;
    mov.b32     %f24, %r9;
    shl.b64     %rd8, %rd2, 2;
    add.s64     %rd9, %rd1, %rd8;
    st.global.f32   [%rd9], %f24;
    ret;
}






